# Personal Statement

My journey with compilers began with **open-source contributions** during my undergraduate studies. In my junior year, I was selected for OSPP 2022, a nationwide open-source initiative analogous to Google Summer of Code, where I refined the MindSpore graph compiler to support complex Python syntax more efficiently. I successfully delivered the project and was recognized as "Developer of the Year" ([link](https://mp.weixin.qq.com/s/kLi95qgg2Rxub9BZs-OGTg)). In my final undergraduate year, I interned at the Institute of Software, Chinese Academy of Sciences (ISCAS), working with the Buddy Compiler. My contributions earned me the honor of "Outstanding Intern" and paved the way for me to join ISCAS for my Master's degree in 2023.

During my Master's studies, I evolved my role from a open-source contributor to a **project mentor**. I guided students in OSPP 2024 on RISC-V kernel optimizations and presented our work at the RISC-V Summit China 2024 ([link](https://www.bilibili.com/video/BV1QwtCeBEoi/)). Furthermore, I interned at Huawei's Beijing Research Center, contributing to the TritonAscend project. This involved adapting Triton—a popular tile-level kernel compiler—for NPU platforms. I am also involved in the internal development of Flaggems, which seeks to extend this Triton-based framework to NPUs. These experiences established a robust technical foundation for my research.

My Master's thesis draws on this experience to address the gap between RISC-V optimization and the Triton compiler. While Triton balances performance with usability, its current CPU support relies on static length vectors, failing to leverage the dynamic length vector features critical to the RISC-V Vector Extension (RVV). To solve this, I proposed **TritonRV**, the first Triton-based compiler and tuning framework specific to the RVV architecture. Central to TritonRV is a novel intermediate representation of dynamic length vectors for strip-mining loop optimization, paired with an RVV-register-aware tuning mechanism based on an expanded search space. TritonRV is also helpful for developers who want to cross-compile Triton on RISC-V platform ([link](https://github.com/xlinsist/Triton-RV/)).

I also participated in two other projects at ISCAS, both centered on optimizing kernels specifically for CPU SIMD platforms. The first project, **AutoConfig**, is a semi-automated configuration framework for deep learning kernel compilation; my specific contribution was designing a cost model to identify optimal parameters. This work was published in the Journal of Software in 2024. The second, **HybridSIMD**, is a C++ library offering a unified interface and collaborative auto-tuning, where I developed the compilation pipeline and tuning module. I presented this work at the ASE 2025 conference.

My doctoral research aims to develop **next-generation AI inference frameworks** that bridge the gap between high-level usability and hardware-specific performance on emerging heterogeneous architectures, specifically by integrating easy-to-use programming abstractions with fully automatic optimization. As high-performance computing shifts from homogeneous processors to heterogeneous architectures, optimizing system design becomes increasingly challenging due to the significant divergence in hardware features and the complexity of the optimization space. Although current designs focus on achieving high performance by tailoring programming models and tuning heuristics primarily for dominant GPU architectures, they often result in poor usability and portability.
- **Usability**: A key challenge is to design a unified programming model that serves as a bridge between user-friendly abstraction and hardware-specific control, catering to both non-expert programmers and optimizing compilers. Traditional models like SIMT for GPUs are difficult to program and hard to port. Although recent efforts like Tile IR (Introduced with CUDA 13.1 in December 2025) offer a tile-level interface for NVIDIA GPUs, they are limited in supporting other architectures. TritonRV explored tile-level programming for RISC-V as my first step along this direction, but more complex hardware platforms still need the flexibility to adapt to similar semantics.
- **Portability**: Even with a unified programming model, mapping programs to diverse hardware involves an enormous search space (e.g., tiling, instruction selection, memory layout). Traditional auto-tuning methods are often costly and rely on manual rules. In my prior work on AutoConfig and HybridSIMD, I experienced the complexity of tuning tensor programs firsthand. A promising direction is to leverage Large Language Model(LLM) sto explore this optimization space, exploiting their high-level semantic reasoning rather than relying on hand-crafted heuristics—an embodiment of "the bitter lesson" in ML systems.

To summarize, my proposed research utilizes a tile-level programming model to abstract hardware similarities for cross-platform portability, while leveraging LLM-driven autotuning to capitalize on architecture-specific opportunities for optimal performance. I believe the future of compilers lies in the principle: "**unify the similar, amplify the unique.**" It uses standardized abstractions for portability while leveraging AI to exploit hardware-specific uniqueness.

Through my doctoral studies, I aim to sharpen my logical thinking and enhance my ability to communicate complex ideas with clarity, both in writing and speaking. Although I have not yet decided between an academic or industrial career, I am certain that rigorous thinking and strong communication skills will be the foundation of my success in either path. Starting from a passion for contributing to and mentoring open-source compiler projects, I have gained valuable research experience and core competencies during my Master’s studies, which I am eager to advance in my PhD.
